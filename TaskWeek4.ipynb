{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyPDVfASoTXYJf2c9TeJXySO",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Riasci/KomputasiIntelegensiaTasks/blob/main/TaskWeek4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Nama: Ria Mulyadi\n",
        "\n",
        "NPM: 2206048556"
      ],
      "metadata": {
        "id": "7tMGKo1vHDKZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install d2l"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "akhAXikhHMUo",
        "outputId": "6fcb81dd-9856-4d21-96ec-f63e11edf95b"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: d2l in /usr/local/lib/python3.10/dist-packages (1.0.3)\n",
            "Requirement already satisfied: jupyter==1.0.0 in /usr/local/lib/python3.10/dist-packages (from d2l) (1.0.0)\n",
            "Requirement already satisfied: numpy==1.23.5 in /usr/local/lib/python3.10/dist-packages (from d2l) (1.23.5)\n",
            "Requirement already satisfied: matplotlib==3.7.2 in /usr/local/lib/python3.10/dist-packages (from d2l) (3.7.2)\n",
            "Requirement already satisfied: matplotlib-inline==0.1.6 in /usr/local/lib/python3.10/dist-packages (from d2l) (0.1.6)\n",
            "Requirement already satisfied: requests==2.31.0 in /usr/local/lib/python3.10/dist-packages (from d2l) (2.31.0)\n",
            "Requirement already satisfied: pandas==2.0.3 in /usr/local/lib/python3.10/dist-packages (from d2l) (2.0.3)\n",
            "Requirement already satisfied: scipy==1.10.1 in /usr/local/lib/python3.10/dist-packages (from d2l) (1.10.1)\n",
            "Requirement already satisfied: notebook in /usr/local/lib/python3.10/dist-packages (from jupyter==1.0.0->d2l) (6.5.5)\n",
            "Requirement already satisfied: qtconsole in /usr/local/lib/python3.10/dist-packages (from jupyter==1.0.0->d2l) (5.6.0)\n",
            "Requirement already satisfied: jupyter-console in /usr/local/lib/python3.10/dist-packages (from jupyter==1.0.0->d2l) (6.1.0)\n",
            "Requirement already satisfied: nbconvert in /usr/local/lib/python3.10/dist-packages (from jupyter==1.0.0->d2l) (6.5.4)\n",
            "Requirement already satisfied: ipykernel in /usr/local/lib/python3.10/dist-packages (from jupyter==1.0.0->d2l) (5.5.6)\n",
            "Requirement already satisfied: ipywidgets in /usr/local/lib/python3.10/dist-packages (from jupyter==1.0.0->d2l) (7.7.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib==3.7.2->d2l) (1.3.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib==3.7.2->d2l) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib==3.7.2->d2l) (4.54.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib==3.7.2->d2l) (1.4.7)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib==3.7.2->d2l) (24.1)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib==3.7.2->d2l) (10.4.0)\n",
            "Requirement already satisfied: pyparsing<3.1,>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib==3.7.2->d2l) (3.0.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib==3.7.2->d2l) (2.8.2)\n",
            "Requirement already satisfied: traitlets in /usr/local/lib/python3.10/dist-packages (from matplotlib-inline==0.1.6->d2l) (5.7.1)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas==2.0.3->d2l) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas==2.0.3->d2l) (2024.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests==2.31.0->d2l) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests==2.31.0->d2l) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests==2.31.0->d2l) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests==2.31.0->d2l) (2024.8.30)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib==3.7.2->d2l) (1.16.0)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.10/dist-packages (from ipykernel->jupyter==1.0.0->d2l) (0.2.0)\n",
            "Requirement already satisfied: ipython>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from ipykernel->jupyter==1.0.0->d2l) (7.34.0)\n",
            "Requirement already satisfied: jupyter-client in /usr/local/lib/python3.10/dist-packages (from ipykernel->jupyter==1.0.0->d2l) (6.1.12)\n",
            "Requirement already satisfied: tornado>=4.2 in /usr/local/lib/python3.10/dist-packages (from ipykernel->jupyter==1.0.0->d2l) (6.3.3)\n",
            "Requirement already satisfied: widgetsnbextension~=3.6.0 in /usr/local/lib/python3.10/dist-packages (from ipywidgets->jupyter==1.0.0->d2l) (3.6.9)\n",
            "Requirement already satisfied: jupyterlab-widgets>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from ipywidgets->jupyter==1.0.0->d2l) (3.0.13)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from jupyter-console->jupyter==1.0.0->d2l) (3.0.48)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.10/dist-packages (from jupyter-console->jupyter==1.0.0->d2l) (2.18.0)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter==1.0.0->d2l) (4.9.4)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter==1.0.0->d2l) (4.12.3)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter==1.0.0->d2l) (6.1.0)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter==1.0.0->d2l) (0.7.1)\n",
            "Requirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter==1.0.0->d2l) (0.4)\n",
            "Requirement already satisfied: jinja2>=3.0 in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter==1.0.0->d2l) (3.1.4)\n",
            "Requirement already satisfied: jupyter-core>=4.7 in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter==1.0.0->d2l) (5.7.2)\n",
            "Requirement already satisfied: jupyterlab-pygments in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter==1.0.0->d2l) (0.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter==1.0.0->d2l) (2.1.5)\n",
            "Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter==1.0.0->d2l) (0.8.4)\n",
            "Requirement already satisfied: nbclient>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter==1.0.0->d2l) (0.10.0)\n",
            "Requirement already satisfied: nbformat>=5.1 in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter==1.0.0->d2l) (5.10.4)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter==1.0.0->d2l) (1.5.1)\n",
            "Requirement already satisfied: tinycss2 in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter==1.0.0->d2l) (1.3.0)\n",
            "Requirement already satisfied: pyzmq<25,>=17 in /usr/local/lib/python3.10/dist-packages (from notebook->jupyter==1.0.0->d2l) (24.0.1)\n",
            "Requirement already satisfied: argon2-cffi in /usr/local/lib/python3.10/dist-packages (from notebook->jupyter==1.0.0->d2l) (23.1.0)\n",
            "Requirement already satisfied: nest-asyncio>=1.5 in /usr/local/lib/python3.10/dist-packages (from notebook->jupyter==1.0.0->d2l) (1.6.0)\n",
            "Requirement already satisfied: Send2Trash>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from notebook->jupyter==1.0.0->d2l) (1.8.3)\n",
            "Requirement already satisfied: terminado>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from notebook->jupyter==1.0.0->d2l) (0.18.1)\n",
            "Requirement already satisfied: prometheus-client in /usr/local/lib/python3.10/dist-packages (from notebook->jupyter==1.0.0->d2l) (0.21.0)\n",
            "Requirement already satisfied: nbclassic>=0.4.7 in /usr/local/lib/python3.10/dist-packages (from notebook->jupyter==1.0.0->d2l) (1.1.0)\n",
            "Requirement already satisfied: qtpy>=2.4.0 in /usr/local/lib/python3.10/dist-packages (from qtconsole->jupyter==1.0.0->d2l) (2.4.1)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.10/dist-packages (from ipython>=5.0.0->ipykernel->jupyter==1.0.0->d2l) (71.0.4)\n",
            "Requirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.10/dist-packages (from ipython>=5.0.0->ipykernel->jupyter==1.0.0->d2l) (0.19.1)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from ipython>=5.0.0->ipykernel->jupyter==1.0.0->d2l) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from ipython>=5.0.0->ipykernel->jupyter==1.0.0->d2l) (0.7.5)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from ipython>=5.0.0->ipykernel->jupyter==1.0.0->d2l) (0.2.0)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from ipython>=5.0.0->ipykernel->jupyter==1.0.0->d2l) (4.9.0)\n",
            "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.10/dist-packages (from jupyter-core>=4.7->nbconvert->jupyter==1.0.0->d2l) (4.3.6)\n",
            "Requirement already satisfied: notebook-shim>=0.2.3 in /usr/local/lib/python3.10/dist-packages (from nbclassic>=0.4.7->notebook->jupyter==1.0.0->d2l) (0.2.4)\n",
            "Requirement already satisfied: fastjsonschema>=2.15 in /usr/local/lib/python3.10/dist-packages (from nbformat>=5.1->nbconvert->jupyter==1.0.0->d2l) (2.20.0)\n",
            "Requirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.10/dist-packages (from nbformat>=5.1->nbconvert->jupyter==1.0.0->d2l) (4.23.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->jupyter-console->jupyter==1.0.0->d2l) (0.2.13)\n",
            "Requirement already satisfied: ptyprocess in /usr/local/lib/python3.10/dist-packages (from terminado>=0.8.3->notebook->jupyter==1.0.0->d2l) (0.7.0)\n",
            "Requirement already satisfied: argon2-cffi-bindings in /usr/local/lib/python3.10/dist-packages (from argon2-cffi->notebook->jupyter==1.0.0->d2l) (21.2.0)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->nbconvert->jupyter==1.0.0->d2l) (2.6)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach->nbconvert->jupyter==1.0.0->d2l) (0.5.1)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->ipython>=5.0.0->ipykernel->jupyter==1.0.0->d2l) (0.8.4)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat>=5.1->nbconvert->jupyter==1.0.0->d2l) (24.2.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat>=5.1->nbconvert->jupyter==1.0.0->d2l) (2023.12.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat>=5.1->nbconvert->jupyter==1.0.0->d2l) (0.35.1)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat>=5.1->nbconvert->jupyter==1.0.0->d2l) (0.20.0)\n",
            "Requirement already satisfied: jupyter-server<3,>=1.8 in /usr/local/lib/python3.10/dist-packages (from notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook->jupyter==1.0.0->d2l) (1.24.0)\n",
            "Requirement already satisfied: cffi>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from argon2-cffi-bindings->argon2-cffi->notebook->jupyter==1.0.0->d2l) (1.17.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->notebook->jupyter==1.0.0->d2l) (2.22)\n",
            "Requirement already satisfied: anyio<4,>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook->jupyter==1.0.0->d2l) (3.7.1)\n",
            "Requirement already satisfied: websocket-client in /usr/local/lib/python3.10/dist-packages (from jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook->jupyter==1.0.0->d2l) (1.8.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<4,>=3.1.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook->jupyter==1.0.0->d2l) (1.3.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<4,>=3.1.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook->jupyter==1.0.0->d2l) (1.2.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 8.1 Deep Convolutional Neural Networks (AlexNet)"
      ],
      "metadata": {
        "id": "Uyz3e99OT2uw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from d2l import torch as d2l"
      ],
      "metadata": {
        "id": "QOZ3HOpYHOGW"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class AlexNet(d2l.Classifier):\n",
        "  def __init__(self, lr=0.1, num_classes=10):\n",
        "    super().__init__()\n",
        "    self.save_hyperparameters()\n",
        "    self.net = nn.Sequential(\n",
        "      nn.LazyConv2d(96, kernel_size=11, stride=4, padding=1),\n",
        "      nn.ReLU(), nn.MaxPool2d(kernel_size=3, stride=2),\n",
        "      nn.LazyConv2d(256, kernel_size=5, padding=2), nn.ReLU(),\n",
        "      nn.MaxPool2d(kernel_size=3, stride=2),\n",
        "      nn.LazyConv2d(384, kernel_size=3, padding=1), nn.ReLU(),\n",
        "      nn.LazyConv2d(384, kernel_size=3, padding=1), nn.ReLU(),\n",
        "      nn.LazyConv2d(256, kernel_size=3, padding=1), nn.ReLU(),\n",
        "      nn.MaxPool2d(kernel_size=3, stride=2), nn.Flatten(),\n",
        "      nn.LazyLinear(4096), nn.ReLU(), nn.Dropout(p=0.5),\n",
        "      nn.LazyLinear(4096), nn.ReLU(),nn.Dropout(p=0.5),\n",
        "      nn.LazyLinear(num_classes))\n",
        "    self.net.apply(d2l.init_cnn)"
      ],
      "metadata": {
        "id": "j9-oOYaaH1g2"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "AlexNet().layer_summary((1, 1, 224, 224))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "28s0QLUmH2cQ",
        "outputId": "895750e4-4a3f-4761-c7ae-5f4cb3cbe851"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Conv2d output shape:\t torch.Size([1, 96, 54, 54])\n",
            "ReLU output shape:\t torch.Size([1, 96, 54, 54])\n",
            "MaxPool2d output shape:\t torch.Size([1, 96, 26, 26])\n",
            "Conv2d output shape:\t torch.Size([1, 256, 26, 26])\n",
            "ReLU output shape:\t torch.Size([1, 256, 26, 26])\n",
            "MaxPool2d output shape:\t torch.Size([1, 256, 12, 12])\n",
            "Conv2d output shape:\t torch.Size([1, 384, 12, 12])\n",
            "ReLU output shape:\t torch.Size([1, 384, 12, 12])\n",
            "Conv2d output shape:\t torch.Size([1, 384, 12, 12])\n",
            "ReLU output shape:\t torch.Size([1, 384, 12, 12])\n",
            "Conv2d output shape:\t torch.Size([1, 256, 12, 12])\n",
            "ReLU output shape:\t torch.Size([1, 256, 12, 12])\n",
            "MaxPool2d output shape:\t torch.Size([1, 256, 5, 5])\n",
            "Flatten output shape:\t torch.Size([1, 6400])\n",
            "Linear output shape:\t torch.Size([1, 4096])\n",
            "ReLU output shape:\t torch.Size([1, 4096])\n",
            "Dropout output shape:\t torch.Size([1, 4096])\n",
            "Linear output shape:\t torch.Size([1, 4096])\n",
            "ReLU output shape:\t torch.Size([1, 4096])\n",
            "Dropout output shape:\t torch.Size([1, 4096])\n",
            "Linear output shape:\t torch.Size([1, 10])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = AlexNet(lr=0.01)\n",
        "data = d2l.FashionMNIST(batch_size=128, resize=(224, 224))\n",
        "trainer = d2l.Trainer(max_epochs=10, num_gpus=1)\n",
        "trainer.fit(model, data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 376
        },
        "collapsed": true,
        "id": "7Rc9yh1RIFC7",
        "outputId": "5375eb81-fb93-401c-f25a-f6f1d349200e"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-1954e5c506dc>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0md2l\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFashionMNIST\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m224\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m224\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtrainer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0md2l\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrainer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_gpus\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/d2l/torch.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, data)\u001b[0m\n\u001b[1;32m    283\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mval_batch_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    284\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 285\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    286\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfit_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/d2l/torch.py\u001b[0m in \u001b[0;36mfit_epoch\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    296\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 298\u001b[0;31m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprepare_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    299\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    300\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/d2l/torch.py\u001b[0m in \u001b[0;36mtraining_step\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    211\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtraining_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 213\u001b[0;31m         \u001b[0ml\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    214\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1552\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1553\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1555\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1560\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1561\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1563\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1564\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/d2l/torch.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    191\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'net'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Neural network is defined'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 193\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    194\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1552\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1553\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1555\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1560\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1561\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1563\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1564\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    217\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 219\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    220\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1552\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1553\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1555\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1560\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1561\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1563\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1564\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    456\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    457\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 458\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    459\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    460\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    452\u001b[0m                             \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[0;32m--> 454\u001b[0;31m         return F.conv2d(input, weight, bias, self.stride,\n\u001b[0m\u001b[1;32m    455\u001b[0m                         self.padding, self.dilation, self.groups)\n\u001b[1;32m    456\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 8.2 Networks Using Blocks (VGG)"
      ],
      "metadata": {
        "id": "WQuXETENTG6Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from d2l import torch as d2l"
      ],
      "metadata": {
        "id": "qpE27KjqIMJ9"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def vgg_block(num_convs, out_channels):\n",
        "  layers = []\n",
        "  for _ in range(num_convs):\n",
        "    layers.append(nn.LazyConv2d(out_channels, kernel_size=3, padding=1))\n",
        "    layers.append(nn.ReLU())\n",
        "  layers.append(nn.MaxPool2d(kernel_size=2,stride=2))\n",
        "  return nn.Sequential(*layers)"
      ],
      "metadata": {
        "id": "dJdG5zp6Ip0k"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class VGG(d2l.Classifier):\n",
        "  def __init__(self, arch, lr=0.1, num_classes=10):\n",
        "    super().__init__()\n",
        "    self.save_hyperparameters()\n",
        "    conv_blks = []\n",
        "    for (num_convs, out_channels) in arch:\n",
        "      conv_blks.append(vgg_block(num_convs, out_channels))\n",
        "    self.net = nn.Sequential(\n",
        "      *conv_blks, nn.Flatten(),\n",
        "      nn.LazyLinear(4096), nn.ReLU(), nn.Dropout(0.5),\n",
        "      nn.LazyLinear(4096), nn.ReLU(), nn.Dropout(0.5),\n",
        "      nn.LazyLinear(num_classes))\n",
        "    self.net.apply(d2l.init_cnn)"
      ],
      "metadata": {
        "id": "cdbEuF8bIz7_"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "VGG(arch=((1, 64), (1, 128), (2, 256), (2, 512), (2, 512))).layer_summary(\n",
        "    (1, 1, 224, 224))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BOpwO4J5JHUd",
        "outputId": "6c4a6c59-5c8c-49f8-db94-7f26768595b0"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sequential output shape:\t torch.Size([1, 64, 112, 112])\n",
            "Sequential output shape:\t torch.Size([1, 128, 56, 56])\n",
            "Sequential output shape:\t torch.Size([1, 256, 28, 28])\n",
            "Sequential output shape:\t torch.Size([1, 512, 14, 14])\n",
            "Sequential output shape:\t torch.Size([1, 512, 7, 7])\n",
            "Flatten output shape:\t torch.Size([1, 25088])\n",
            "Linear output shape:\t torch.Size([1, 4096])\n",
            "ReLU output shape:\t torch.Size([1, 4096])\n",
            "Dropout output shape:\t torch.Size([1, 4096])\n",
            "Linear output shape:\t torch.Size([1, 4096])\n",
            "ReLU output shape:\t torch.Size([1, 4096])\n",
            "Dropout output shape:\t torch.Size([1, 4096])\n",
            "Linear output shape:\t torch.Size([1, 10])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = VGG(arch=((1, 16), (1, 32), (2, 64), (2, 128), (2, 128)), lr=0.01)\n",
        "trainer = d2l.Trainer(max_epochs=10, num_gpus=1)\n",
        "data = d2l.FashionMNIST(batch_size=128, resize=(224, 224))\n",
        "model.apply_init([next(iter(data.get_dataloader(True)))[0]], d2l.init_cnn)\n",
        "trainer.fit(model, data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 321
        },
        "collapsed": true,
        "id": "isQQEkqLJN9x",
        "outputId": "ec75cac5-9e4a-4661-cf8a-75bbde324265"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-8d3dfa6be93b>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0md2l\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFashionMNIST\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m224\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m224\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_init\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_dataloader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md2l\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit_cnn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/d2l/torch.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, data)\u001b[0m\n\u001b[1;32m    283\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mval_batch_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    284\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 285\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    286\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfit_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/d2l/torch.py\u001b[0m in \u001b[0;36mfit_epoch\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    299\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    300\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 301\u001b[0;31m                 \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    302\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradient_clip_val\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# To be discussed later\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    303\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradient_clip_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    519\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m             )\n\u001b[0;32m--> 521\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    522\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    287\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 289\u001b[0;31m     _engine_run_backward(\n\u001b[0m\u001b[1;32m    290\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    291\u001b[0m         \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py\u001b[0m in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    767\u001b[0m         \u001b[0munregister_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_register_logging_hooks_on_whole_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    768\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 769\u001b[0;31m         return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    770\u001b[0m             \u001b[0mt_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    771\u001b[0m         )  # Calls into the C++ engine to run the backward pass\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 8.3 Network in Network (NiN)\n"
      ],
      "metadata": {
        "id": "nuKzDHaQTbIx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from d2l import torch as d2l"
      ],
      "metadata": {
        "id": "iA51JhQaJPHw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def nin_block(out_channels, kernel_size, strides, padding):\n",
        "  return nn.Sequential(\n",
        "    nn.LazyConv2d(out_channels, kernel_size, strides, padding), nn.ReLU(),\n",
        "    nn.LazyConv2d(out_channels, kernel_size=1), nn.ReLU(),\n",
        "    nn.LazyConv2d(out_channels, kernel_size=1), nn.ReLU())"
      ],
      "metadata": {
        "id": "cKA0CHmDJTIO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class NiN(d2l.Classifier):\n",
        "  def __init__(self, lr=0.1, num_classes=10):\n",
        "    super().__init__()\n",
        "    self.save_hyperparameters()\n",
        "    self.net = nn.Sequential(\n",
        "      nin_block(96, kernel_size=11, strides=4, padding=0),\n",
        "      nn.MaxPool2d(3, stride=2),\n",
        "      nin_block(256, kernel_size=5, strides=1, padding=2),\n",
        "      nn.MaxPool2d(3, stride=2),\n",
        "      nin_block(384, kernel_size=3, strides=1, padding=1),\n",
        "      nn.MaxPool2d(3, stride=2),\n",
        "      nn.Dropout(0.5),\n",
        "      nin_block(num_classes, kernel_size=3, strides=1, padding=1),\n",
        "      nn.AdaptiveAvgPool2d((1, 1)),\n",
        "      nn.Flatten())\n",
        "    self.net.apply(d2l.init_cnn)"
      ],
      "metadata": {
        "id": "V-CPBaxPJY0I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "NiN().layer_summary((1, 1, 224, 224))"
      ],
      "metadata": {
        "id": "7MxeY3WEJiXy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = NiN(lr=0.05)\n",
        "trainer = d2l.Trainer(max_epochs=10, num_gpus=1)\n",
        "data = d2l.FashionMNIST(batch_size=128, resize=(224, 224))\n",
        "model.apply_init([next(iter(data.get_dataloader(True)))[0]], d2l.init_cnn)\n",
        "trainer.fit(model, data)"
      ],
      "metadata": {
        "id": "TpUe05UtJmAY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 8.4 Multi-Branch Networks (GoogLeNet)\n"
      ],
      "metadata": {
        "id": "Sn7TU_IKJwlP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch.nn import functional as F\n",
        "from d2l import torch as d2l"
      ],
      "metadata": {
        "id": "zYyP6zk4Jprg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Inception(nn.Module):\n",
        "  # c1--c4 are the number of output channels for each branch\n",
        "  def __init__(self, c1, c2, c3, c4, **kwargs):\n",
        "    super(Inception, self).__init__(**kwargs)\n",
        "    # Branch 1\n",
        "    self.b1_1 = nn.LazyConv2d(c1, kernel_size=1)\n",
        "    # Branch 2\n",
        "    self.b2_1 = nn.LazyConv2d(c2[0], kernel_size=1)\n",
        "    self.b2_2 = nn.LazyConv2d(c2[1], kernel_size=3, padding=1)\n",
        "    # Branch 3\n",
        "    self.b3_1 = nn.LazyConv2d(c3[0], kernel_size=1)\n",
        "    self.b3_2 = nn.LazyConv2d(c3[1], kernel_size=5, padding=2)\n",
        "    # Branch 4\n",
        "    self.b4_1 = nn.MaxPool2d(kernel_size=3, stride=1, padding=1)\n",
        "    self.b4_2 = nn.LazyConv2d(c4, kernel_size=1)\n",
        "\n",
        "  def forward(self, x):\n",
        "    b1 = F.relu(self.b1_1(x))\n",
        "    b2 = F.relu(self.b2_2(F.relu(self.b2_1(x))))\n",
        "    b3 = F.relu(self.b3_2(F.relu(self.b3_1(x))))\n",
        "    b4 = F.relu(self.b4_2(self.b4_1(x)))\n",
        "    return torch.cat((b1, b2, b3, b4), dim=1)"
      ],
      "metadata": {
        "id": "i2uuvujFJ01U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class GoogleNet(d2l.Classifier):\n",
        "  def b1(self):\n",
        "    return nn.Sequential(\n",
        "      nn.LazyConv2d(64, kernel_size=7, stride=2, padding=3),\n",
        "      nn.ReLU(), nn.MaxPool2d(kernel_size=3, stride=2, padding=1))"
      ],
      "metadata": {
        "id": "aGyo1bu9KEYb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@d2l.add_to_class(GoogleNet)\n",
        "def b2(self):\n",
        "  return nn.Sequential(\n",
        "    nn.LazyConv2d(64, kernel_size=1), nn.ReLU(),\n",
        "    nn.LazyConv2d(192, kernel_size=3, padding=1), nn.ReLU(),\n",
        "    nn.MaxPool2d(kernel_size=3, stride=2, padding=1))"
      ],
      "metadata": {
        "id": "pWBxBMRLKQty"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@d2l.add_to_class(GoogleNet)\n",
        "def b3(self):\n",
        "  return nn.Sequential(Inception(64, (96, 128), (16, 32), 32),\n",
        "                      Inception(128, (128, 192), (32, 96), 64),\n",
        "                      nn.MaxPool2d(kernel_size=3, stride=2, padding=1))"
      ],
      "metadata": {
        "id": "NYShtEZlKXWx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@d2l.add_to_class(GoogleNet)\n",
        "def b4(self):\n",
        "  return nn.Sequential(Inception(192, (96, 208), (16, 48), 64),\n",
        "                      Inception(160, (112, 224), (24, 64), 64),\n",
        "                      Inception(128, (128, 256), (24, 64), 64),\n",
        "                      Inception(112, (144, 288), (32, 64), 64),\n",
        "                      Inception(256, (160, 320), (32, 128), 128),\n",
        "                      nn.MaxPool2d(kernel_size=3, stride=2, padding=1))"
      ],
      "metadata": {
        "id": "Rne9wG-JKlQ_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@d2l.add_to_class(GoogleNet)\n",
        "def b5(self):\n",
        "  return nn.Sequential(Inception(256, (160, 320), (32, 128), 128),\n",
        "                      Inception(384, (192, 384), (48, 128), 128),\n",
        "                      nn.AdaptiveAvgPool2d((1,1)), nn.Flatten())"
      ],
      "metadata": {
        "id": "0svbbmPVKwng"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@d2l.add_to_class(GoogleNet)\n",
        "def __init__(self, lr=0.1, num_classes=10):\n",
        "  super(GoogleNet, self).__init__()\n",
        "  self.save_hyperparameters()\n",
        "  self.net = nn.Sequential(self.b1(), self.b2(), self.b3(), self.b4(),\n",
        "                          self.b5(), nn.LazyLinear(num_classes))\n",
        "  self.net.apply(d2l.init_cnn)"
      ],
      "metadata": {
        "id": "TX9QtXgUK7PR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = GoogleNet().layer_summary((1, 1, 96, 96))"
      ],
      "metadata": {
        "id": "9X4iCPuKLGZA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = GoogleNet(lr=0.01)\n",
        "trainer = d2l.Trainer(max_epochs=10, num_gpus=1)\n",
        "data = d2l.FashionMNIST(batch_size=128, resize=(96, 96))\n",
        "model.apply_init([next(iter(data.get_dataloader(True)))[0]], d2l.init_cnn)\n",
        "trainer.fit(model, data)"
      ],
      "metadata": {
        "id": "1Lj2y8gALP_4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 8.5 Batch Normalization\n"
      ],
      "metadata": {
        "id": "HStjwW6-LSJ2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from d2l import torch as d2l"
      ],
      "metadata": {
        "id": "eZ8UhFonLVLE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def batch_norm(X, gamma, beta, moving_mean, moving_var, eps, momentum):\n",
        "  # Use is_grad_enabled to determine whether we are in training mode\n",
        "  if not torch.is_grad_enabled():\n",
        "    # In prediction mode, use mean and variance obtained by moving average\n",
        "    X_hat = (X - moving_mean) / torch.sqrt(moving_var + eps)\n",
        "  else:\n",
        "    assert len(X.shape) in (2, 4)\n",
        "    if len(X.shape) == 2:\n",
        "      # When using a fully connected layer, calculate the mean and\n",
        "      # variance on the feature dimension\n",
        "      mean = X.mean(dim=0)\n",
        "      var = ((X - mean) ** 2).mean(dim=0)\n",
        "    else:\n",
        "      # When using a two-dimensional convolutional layer, calculate the\n",
        "      # mean and variance on the channel dimension (axis=1). Here we\n",
        "      # need to maintain the shape of X, so that the broadcasting\n",
        "      # operation can be carried out later\n",
        "      mean = X.mean(dim=(0, 2, 3), keepdim=True)\n",
        "      var = ((X - mean) ** 2).mean(dim=(0, 2, 3), keepdim=True)\n",
        "    # In training mode, the current mean and variance are used\n",
        "    X_hat = (X - mean) / torch.sqrt(var + eps)\n",
        "    # Update the mean and variance using moving average\n",
        "    moving_mean = (1.0 - momentum) * moving_mean + momentum * mean\n",
        "    moving_var = (1.0 - momentum) * moving_var + momentum * var\n",
        "  Y = gamma * X_hat + beta # Scale and shift\n",
        "  return Y, moving_mean.data, moving_var.data"
      ],
      "metadata": {
        "id": "-kZSynhfLacB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class BatchNorm(nn.Module):\n",
        "  # num_features: the number of outputs for a fully connected layer or the\n",
        "  # number of output channels for a convolutional layer. num_dims: 2 for a\n",
        "  # fully connected layer and 4 for a convolutional layer\n",
        "  def __init__(self, num_features, num_dims):\n",
        "    super().__init__()\n",
        "    if num_dims == 2:\n",
        "      shape = (1, num_features)\n",
        "    else:\n",
        "      shape = (1, num_features, 1, 1)\n",
        "    # The scale parameter and the shift parameter (model parameters) are\n",
        "    # initialized to 1 and 0, respectively\n",
        "    self.gamma = nn.Parameter(torch.ones(shape))\n",
        "    self.beta = nn.Parameter(torch.zeros(shape))\n",
        "    # The variables that are not model parameters are initialized to 0 and\n",
        "    # 1\n",
        "    self.moving_mean = torch.zeros(shape)\n",
        "    self.moving_var = torch.ones(shape)\n",
        "  def forward(self, X):\n",
        "    # If X is not on the main memory, copy moving_mean and moving_var to\n",
        "    # the device where X is located\n",
        "    if self.moving_mean.device != X.device:\n",
        "      self.moving_mean = self.moving_mean.to(X.device)\n",
        "      self.moving_var = self.moving_var.to(X.device)\n",
        "    # Save the updated moving_mean and moving_var\n",
        "    Y, self.moving_mean, self.moving_var = batch_norm(\n",
        "      X, self.gamma, self.beta, self.moving_mean,\n",
        "      self.moving_var, eps=1e-5, momentum=0.1)\n",
        "    return Y"
      ],
      "metadata": {
        "id": "WV3_WNauLz-z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class BNLeNetScratch(d2l.Classifier):\n",
        "  def __init__(self, lr=0.1, num_classes=10):\n",
        "    super().__init__()\n",
        "    self.save_hyperparameters()\n",
        "    self.net = nn.Sequential(\n",
        "      nn.LazyConv2d(6, kernel_size=5), BatchNorm(6, num_dims=4),\n",
        "      nn.Sigmoid(), nn.AvgPool2d(kernel_size=2, stride=2),\n",
        "      nn.LazyConv2d(16, kernel_size=5), BatchNorm(16, num_dims=4),\n",
        "      nn.Sigmoid(), nn.AvgPool2d(kernel_size=2, stride=2),\n",
        "      nn.Flatten(), nn.LazyLinear(120),\n",
        "      BatchNorm(120, num_dims=2), nn.Sigmoid(), nn.LazyLinear(84),\n",
        "      BatchNorm(84, num_dims=2), nn.Sigmoid(),\n",
        "      nn.LazyLinear(num_classes))"
      ],
      "metadata": {
        "id": "BFwvYrztMSaD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer = d2l.Trainer(max_epochs=10, num_gpus=1)\n",
        "data = d2l.FashionMNIST(batch_size=128)\n",
        "model = BNLeNetScratch(lr=0.1)\n",
        "model.apply_init([next(iter(data.get_dataloader(True)))[0]], d2l.init_cnn)\n",
        "trainer.fit(model, data)"
      ],
      "metadata": {
        "id": "LNUj0F1bMfnX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.net[1].gamma.reshape((-1,)), model.net[1].beta.reshape((-1,))"
      ],
      "metadata": {
        "id": "ILQa0NPvMioZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class BNLeNet(d2l.Classifier):\n",
        "  def __init__(self, lr=0.1, num_classes=10):\n",
        "    super().__init__()\n",
        "    self.save_hyperparameters()\n",
        "    self.net = nn.Sequential(\n",
        "      nn.LazyConv2d(6, kernel_size=5), nn.LazyBatchNorm2d(),\n",
        "      nn.Sigmoid(), nn.AvgPool2d(kernel_size=2, stride=2),\n",
        "      nn.LazyConv2d(16, kernel_size=5), nn.LazyBatchNorm2d(),\n",
        "      nn.Sigmoid(), nn.AvgPool2d(kernel_size=2, stride=2),\n",
        "      nn.Flatten(), nn.LazyLinear(120), nn.LazyBatchNorm1d(),\n",
        "      nn.Sigmoid(), nn.LazyLinear(84), nn.LazyBatchNorm1d(),\n",
        "      nn.Sigmoid(), nn.LazyLinear(num_classes))"
      ],
      "metadata": {
        "id": "fh9Ue35qMjdw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer = d2l.Trainer(max_epochs=10, num_gpus=1)\n",
        "data = d2l.FashionMNIST(batch_size=128)\n",
        "model = BNLeNet(lr=0.1)\n",
        "model.apply_init([next(iter(data.get_dataloader(True)))[0]], d2l.init_cnn)\n",
        "trainer.fit(model, data)"
      ],
      "metadata": {
        "id": "suE7H5VMMy5D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 8.6 Residual Networks (ResNet) and ResNeXt"
      ],
      "metadata": {
        "id": "JwhPkUxRM2Lz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch.nn import functional as F\n",
        "from d2l import torch as d2l"
      ],
      "metadata": {
        "id": "6eK5NP4JM5Yo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Residual(nn.Module): #@save\n",
        "  \"\"\"The Residual block of ResNet models.\"\"\"\n",
        "  def __init__(self, num_channels, use_1x1conv=False, strides=1):\n",
        "    super().__init__()\n",
        "    self.conv1 = nn.LazyConv2d(num_channels, kernel_size=3, padding=1,\n",
        "                              stride=strides)\n",
        "    self.conv2 = nn.LazyConv2d(num_channels, kernel_size=3, padding=1)\n",
        "    if use_1x1conv:\n",
        "      self.conv3 = nn.LazyConv2d(num_channels, kernel_size=1,\n",
        "                                stride=strides)\n",
        "    else:\n",
        "      self.conv3 = None\n",
        "    self.bn1 = nn.LazyBatchNorm2d()\n",
        "    self.bn2 = nn.LazyBatchNorm2d()\n",
        "\n",
        "  def forward(self, X):\n",
        "    Y = F.relu(self.bn1(self.conv1(X)))\n",
        "    Y = self.bn2(self.conv2(Y))\n",
        "    if self.conv3:\n",
        "      X = self.conv3(X)\n",
        "    Y += X\n",
        "    return F.relu(Y)"
      ],
      "metadata": {
        "id": "Dr_0z5DEM9y4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "blk = Residual(3)\n",
        "X = torch.randn(4, 3, 6, 6)\n",
        "blk(X).shape"
      ],
      "metadata": {
        "id": "Q_b_2dMQNoj9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "blk = Residual(6, use_1x1conv=True, strides=2)\n",
        "blk(X).shape"
      ],
      "metadata": {
        "id": "qVPgJlTPNref"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ResNet(d2l.Classifier):\n",
        "  def b1(self):\n",
        "    return nn.Sequential(\n",
        "      nn.LazyConv2d(64, kernel_size=7, stride=2, padding=3),\n",
        "      nn.LazyBatchNorm2d(), nn.ReLU(),\n",
        "      nn.MaxPool2d(kernel_size=3, stride=2, padding=1))"
      ],
      "metadata": {
        "id": "YR3_EgHrNwaE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@d2l.add_to_class(ResNet)\n",
        "def block(self, num_residuals, num_channels, first_block=False):\n",
        "  blk = []\n",
        "  for i in range(num_residuals):\n",
        "    if i == 0 and not first_block:\n",
        "      blk.append(Residual(num_channels, use_1x1conv=True, strides=2))\n",
        "    else:\n",
        "      blk.append(Residual(num_channels))\n",
        "  return nn.Sequential(*blk)"
      ],
      "metadata": {
        "id": "WaV9k4XPN7GO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@d2l.add_to_class(ResNet)\n",
        "def __init__(self, arch, lr=0.1, num_classes=10):\n",
        "  super(ResNet, self).__init__()\n",
        "  self.save_hyperparameters()\n",
        "  self.net = nn.Sequential(self.b1())\n",
        "  for i, b in enumerate(arch):\n",
        "    self.net.add_module(f'b{i+2}', self.block(*b, first_block=(i==0)))\n",
        "  self.net.add_module('last', nn.Sequential(\n",
        "    nn.AdaptiveAvgPool2d((1, 1)), nn.Flatten(),\n",
        "    nn.LazyLinear(num_classes)))\n",
        "  self.net.apply(d2l.init_cnn)"
      ],
      "metadata": {
        "id": "FGSiL0ytOLMf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ResNet18(ResNet):\n",
        "  def __init__(self, lr=0.1, num_classes=10):\n",
        "    super().__init__(((2, 64), (2, 128), (2, 256), (2, 512)),\n",
        "                    lr, num_classes)"
      ],
      "metadata": {
        "id": "NtMITbV3OR5k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ResNet18().layer_summary((1, 1, 96, 96))"
      ],
      "metadata": {
        "id": "v5WYk5nkOdUO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = ResNet18(lr=0.01)\n",
        "trainer = d2l.Trainer(max_epochs=10, num_gpus=1)\n",
        "data = d2l.FashionMNIST(batch_size=128, resize=(96, 96))\n",
        "model.apply_init([next(iter(data.get_dataloader(True)))[0]], d2l.init_cnn)\n",
        "trainer.fit(model, data)"
      ],
      "metadata": {
        "id": "u8vGezJGOfz-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ResNeXtBlock(nn.Module): #@save\n",
        "  \"\"\"The ResNeXt block.\"\"\"\n",
        "  def __init__(self, num_channels, groups, bot_mul, use_1x1conv=False,\n",
        "              strides=1):\n",
        "    super().__init__()\n",
        "    bot_channels = int(round(num_channels * bot_mul))\n",
        "    self.conv1 = nn.LazyConv2d(bot_channels, kernel_size=1, stride=1)\n",
        "    self.conv2 = nn.LazyConv2d(bot_channels, kernel_size=3,\n",
        "                              stride=strides, padding=1,\n",
        "                              groups=bot_channels//groups)\n",
        "    self.conv3 = nn.LazyConv2d(num_channels, kernel_size=1, stride=1)\n",
        "    self.bn1 = nn.LazyBatchNorm2d()\n",
        "    self.bn2 = nn.LazyBatchNorm2d()\n",
        "    self.bn3 = nn.LazyBatchNorm2d()\n",
        "    if use_1x1conv:\n",
        "      self.conv4 = nn.LazyConv2d(num_channels, kernel_size=1,\n",
        "                                stride=strides)\n",
        "      self.bn4 = nn.LazyBatchNorm2d()\n",
        "    else:\n",
        "      self.conv4 = None\n",
        "\n",
        "  def forward(self, X):\n",
        "    Y = F.relu(self.bn1(self.conv1(X)))\n",
        "    Y = F.relu(self.bn2(self.conv2(Y)))\n",
        "    Y = self.bn3(self.conv3(Y))\n",
        "    if self.conv4:\n",
        "      X = self.bn4(self.conv4(X))\n",
        "    return F.relu(Y + X)"
      ],
      "metadata": {
        "id": "AAMvG4l-Olva"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "blk = ResNeXtBlock(32, 16, 1)\n",
        "X = torch.randn(4, 32, 96, 96)\n",
        "blk(X).shape"
      ],
      "metadata": {
        "id": "1nzxv_bEO-As"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 8.7 Densely Connected Networks (DenseNet)\n"
      ],
      "metadata": {
        "id": "BfZpDFvEPR4E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from d2l import torch as d2l"
      ],
      "metadata": {
        "id": "_VovrB1OPV3D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def conv_block(num_channels):\n",
        "  return nn.Sequential(\n",
        "    nn.LazyBatchNorm2d(), nn.ReLU(),\n",
        "    nn.LazyConv2d(num_channels, kernel_size=3, padding=1))"
      ],
      "metadata": {
        "id": "9S42-OVCP5X2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DenseBlock(nn.Module):\n",
        "  def __init__(self, num_convs, num_channels):\n",
        "    super(DenseBlock, self).__init__()\n",
        "    layer = []\n",
        "    for i in range(num_convs):\n",
        "      layer.append(conv_block(num_channels))\n",
        "    self.net = nn.Sequential(*layer)\n",
        "  def forward(self, X):\n",
        "    for blk in self.net:\n",
        "      Y = blk(X)\n",
        "      # Concatenate input and output of each block along the channels\n",
        "      X = torch.cat((X, Y), dim=1)\n",
        "    return X"
      ],
      "metadata": {
        "id": "XoxTLmZ3QCVN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "blk = DenseBlock(2, 10)\n",
        "X = torch.randn(4, 3, 8, 8)\n",
        "Y = blk(X)\n",
        "Y.shape"
      ],
      "metadata": {
        "id": "UVpJqQmcQdvJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def transition_block(num_channels):\n",
        "  return nn.Sequential(\n",
        "    nn.LazyBatchNorm2d(), nn.ReLU(),\n",
        "    nn.LazyConv2d(num_channels, kernel_size=1),\n",
        "    nn.AvgPool2d(kernel_size=2, stride=2))"
      ],
      "metadata": {
        "id": "mJpqhL_3QhM0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "blk = transition_block(10)\n",
        "blk(Y).shape"
      ],
      "metadata": {
        "id": "b4kYthxfQmKA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DenseNet(d2l.Classifier):\n",
        "  def b1(self):\n",
        "    return nn.Sequential(\n",
        "      nn.LazyConv2d(64, kernel_size=7, stride=2, padding=3),\n",
        "      nn.LazyBatchNorm2d(), nn.ReLU(),\n",
        "      nn.MaxPool2d(kernel_size=3, stride=2, padding=1))"
      ],
      "metadata": {
        "id": "PhsvZGCfQpb5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@d2l.add_to_class(DenseNet)\n",
        "def __init__(self, num_channels=64, growth_rate=32, arch=(4, 4, 4, 4),\n",
        "            lr=0.1, num_classes=10):\n",
        "  super(DenseNet, self).__init__()\n",
        "  self.save_hyperparameters()\n",
        "  self.net = nn.Sequential(self.b1())\n",
        "  for i, num_convs in enumerate(arch):\n",
        "    self.net.add_module(f'dense_blk{i+1}', DenseBlock(num_convs,\n",
        "                                                     growth_rate))\n",
        "    # The number of output channels in the previous dense block\n",
        "    num_channels += num_convs * growth_rate\n",
        "    # A transition layer that halves the number of channels is added\n",
        "    # between the dense blocks\n",
        "    if i != len(arch) - 1:\n",
        "      num_channels //= 2\n",
        "      self.net.add_module(f'tran_blk{i+1}', transition_block(\n",
        "          num_channels))\n",
        "  self.net.add_module('last', nn.Sequential(\n",
        "    nn.LazyBatchNorm2d(), nn.ReLU(),\n",
        "    nn.AdaptiveAvgPool2d((1, 1)), nn.Flatten(),\n",
        "    nn.LazyLinear(num_classes)))\n",
        "  self.net.apply(d2l.init_cnn)"
      ],
      "metadata": {
        "id": "HAdPQCcrQzrT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = DenseNet(lr=0.01)\n",
        "trainer = d2l.Trainer(max_epochs=10, num_gpus=1)\n",
        "data = d2l.FashionMNIST(batch_size=128, resize=(96, 96))\n",
        "trainer.fit(model, data)"
      ],
      "metadata": {
        "id": "NRIhwarrRQiv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 8.8 Designing Convolution Network Architectures"
      ],
      "metadata": {
        "id": "fWafpHjNRWmN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch.nn import functional as F\n",
        "from d2l import torch as d2l"
      ],
      "metadata": {
        "id": "RJaJRYoyRaQO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class AnyNet(d2l.Classifier):\n",
        "  def stem(self, num_channels):\n",
        "    return nn.Sequential(\n",
        "      nn.LazyConv2d(num_channels, kernel_size=3, stride=2, padding=1),\n",
        "      nn.LazyBatchNorm2d(), nn.ReLU())"
      ],
      "metadata": {
        "id": "1LiRkIgSRsOv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@d2l.add_to_class(AnyNet)\n",
        "def stage(self, depth, num_channels, groups, bot_mul):\n",
        "  blk = []\n",
        "  for i in range(depth):\n",
        "    if i == 0:\n",
        "      blk.append(d2l.ResNeXtBlock(num_channels, groups, bot_mul,\n",
        "          use_1x1conv=True, strides=2))\n",
        "    else:\n",
        "      blk.append(d2l.ResNeXtBlock(num_channels, groups, bot_mul))\n",
        "  return nn.Sequential(*blk)"
      ],
      "metadata": {
        "id": "cXWD1D88RxbD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@d2l.add_to_class(AnyNet)\n",
        "def __init__(self, arch, stem_channels, lr=0.1, num_classes=10):\n",
        "  super(AnyNet, self).__init__()\n",
        "  self.save_hyperparameters()\n",
        "  self.net = nn.Sequential(self.stem(stem_channels))\n",
        "  for i, s in enumerate(arch):\n",
        "    self.net.add_module(f'stage{i+1}', self.stage(*s))\n",
        "  self.net.add_module('head', nn.Sequential(\n",
        "    nn.AdaptiveAvgPool2d((1, 1)), nn.Flatten(),\n",
        "    nn.LazyLinear(num_classes)))\n",
        "  self.net.apply(d2l.init_cnn)"
      ],
      "metadata": {
        "id": "Fl3qYIz1SNAH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class RegNetX32(AnyNet):\n",
        "  def __init__(self, lr=0.1, num_classes=10):\n",
        "    stem_channels, groups, bot_mul = 32, 16, 1\n",
        "    depths, channels = (4, 6), (32, 80)\n",
        "    super().__init__(\n",
        "      ((depths[0], channels[0], groups, bot_mul),\n",
        "        (depths[1], channels[1], groups, bot_mul)),\n",
        "      stem_channels, lr, num_classes)"
      ],
      "metadata": {
        "id": "Eh5iMUnGSZIl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "RegNetX32().layer_summary((1, 1, 96, 96))"
      ],
      "metadata": {
        "id": "_TRhs57PStte"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = RegNetX32(lr=0.05)\n",
        "trainer = d2l.Trainer(max_epochs=10, num_gpus=1)\n",
        "data = d2l.FashionMNIST(batch_size=128, resize=(96, 96))\n",
        "trainer.fit(model, data)"
      ],
      "metadata": {
        "id": "RziwFZw_Svwm"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}